{
    "cells": [
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "# Social Network Analysis\n",
       "\n",
       "This notebook creates and analyzes network representations from the collected social media data."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
       "import os\n",
       "import sys\n",
       "from pathlib import Path\n",
       "import json\n",
       "import pandas as pd\n",
       "import networkx as nx\n",
       "import matplotlib.pyplot as plt\n",
       "\n",
       "# Add project root to Python path\n",
       "project_root = Path.cwd().parent\n",
       "sys.path.append(str(project_root))\n",
       "\n",
       "# Import network creation functions\n",
       "from src.analyzers.network_creator import (\n",
       "    create_x_network,\n",
       "    create_youtube_network,\n",
       "    create_reddit_network,\n",
       "    create_tiktok_network,\n",
       "    analyze_network,\n",
       "    export_network\n",
       ")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 1. Load Collected Data\n",
       "\n",
       "First, let's load the most recent data collection results."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
       "def load_latest_collection():\n",
       "    \"\"\"Load the most recent data collection metadata and files.\"\"\"\n",
       "    # Find the latest metadata file\n",
       "    metadata_files = list(Path('data/raw').glob('collection_metadata_*.json'))\n",
       "    if not metadata_files:\n",
       "        raise FileNotFoundError(\"No collection metadata found\")\n",
       "    \n",
       "    latest_metadata = max(metadata_files, key=lambda p: p.stat().st_mtime)\n",
       "    \n",
       "    # Load metadata\n",
       "    with open(latest_metadata) as f:\n",
       "        metadata = json.load(f)\n",
       "    \n",
       "    # Load CSV files\n",
       "    data = {}\n",
       "    for target, platform_files in metadata['files'].items():\n",
       "        data[target] = {}\n",
       "        for platform, file_path in platform_files.items():\n",
       "            data[target][platform] = pd.read_csv(file_path)\n",
       "    \n",
       "    return metadata, data\n",
       "\n",
       "# Load the data\n",
       "metadata, collected_data = load_latest_collection()\n",
       "print(f\"Loaded data collection from: {metadata['timestamp']}\")\n",
       "print(f\"Targets: {metadata['targets']}\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 2. Create Networks\n",
       "\n",
       "Create network representations for each platform and target."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
       "def create_networks(data: dict, timestamp: str):\n",
       "    \"\"\"Create networks for all platforms and targets.\"\"\"\n",
       "    network_files = {}\n",
       "    \n",
       "    for target, platform_data in data.items():\n",
       "        network_files[target] = {}\n",
       "        print(f\"\\nCreating networks for: {target}\")\n",
       "        \n",
       "        # Create X network\n",
       "        if 'x' in platform_data:\n",
       "            print(\"Creating X network...\")\n",
       "            network_files[target]['x'] = create_x_network(\n",
       "                platform_data['x'], target, timestamp\n",
       "            )\n",
       "        \n",
       "        # Create YouTube network\n",
       "        if 'youtube' in platform_data:\n",
       "            print(\"Creating YouTube network...\")\n",
       "            network_files[target]['youtube'] = create_youtube_network(\n",
       "                platform_data['youtube'], target, timestamp\n",
       "            )\n",
       "        \n",
       "        # Create Reddit network\n",
       "        if 'reddit' in platform_data:\n",
       "            print(\"Creating Reddit network...\")\n",
       "            network_files[target]['reddit'] = create_reddit_network(\n",
       "                platform_data['reddit'], target, timestamp\n",
       "            )\n",
       "        \n",
       "        # Create TikTok network\n",
       "        if 'tiktok' in platform_data:\n",
       "            print(\"Creating TikTok network...\")\n",
       "            network_files[target]['tiktok'] = create_tiktok_network(\n",
       "                platform_data['tiktok'], target, timestamp\n",
       "            )\n",
       "    \n",
       "    return network_files\n",
       "\n",
       "# Create networks using the same timestamp as the collection\n",
       "network_files = create_networks(collected_data, metadata['timestamp'])"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 3. Analyze Networks\n",
       "\n",
       "Calculate and compare network metrics across platforms and targets."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
       "def analyze_networks(network_files: dict):\n",
       "    \"\"\"Analyze all created networks.\"\"\"\n",
       "    analysis_results = {}\n",
       "    \n",
       "    for target, platform_files in network_files.items():\n",
       "        analysis_results[target] = {}\n",
       "        print(f\"\\nAnalyzing networks for: {target}\")\n",
       "        \n",
       "        for platform, file_path in platform_files.items():\n",
       "            print(f\"Analyzing {platform} network...\")\n",
       "            G = nx.read_graphml(file_path)\n",
       "            metrics = analyze_network(G)\n",
       "            analysis_results[target][platform] = metrics\n",
       "            \n",
       "            # Print basic metrics\n",
       "            print(f\"  Nodes: {metrics['nodes']}\")\n",
       "            print(f\"  Edges: {metrics['edges']}\")\n",
       "            print(f\"  Density: {metrics['density']:.4f}\")\n",
       "    \n",
       "    return analysis_results\n",
       "\n",
       "# Analyze all networks\n",
       "analysis_results = analyze_networks(network_files)"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 4. Export Networks\n",
       "\n",
       "Export networks in different formats for use in other tools."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
       "def export_all_networks(network_files: dict):\n",
       "    \"\"\"Export all networks in multiple formats.\"\"\"\n",
       "    exported_files = {}\n",
       "    \n",
       "    for target, platform_files in network_files.items():\n",
       "        exported_files[target] = {}\n",
       "        print(f\"\\nExporting networks for: {target}\")\n",
       "        \n",
       "        for platform, file_path in platform_files.items():\n",
       "            print(f\"Exporting {platform} network...\")\n",
       "            export_paths = export_network(file_path, target, platform)\n",
       "            exported_files[target][platform] = export_paths\n",
       "            \n",
       "            # Print export paths\n",
       "            for format_name, path in export_paths.items():\n",
       "                print(f\"  {format_name}: {path}\")\n",
       "    \n",
       "    return exported_files\n",
       "\n",
       "# Export networks in different formats\n",
       "exported_files = export_all_networks(network_files)"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 5. Save Analysis Results\n",
       "\n",
       "Save the network analysis results for future reference."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "source": [
       "# Save analysis results\n",
       "analysis_output = {\n",
       "    'timestamp': metadata['timestamp'],\n",
       "    'targets': metadata['targets'],\n",
       "    'network_files': network_files,\n",
       "    'exported_files': exported_files,\n",
       "    'analysis_results': analysis_results\n",
       "}\n",
       "\n",
       "output_file = f'data/networks/network_analysis_{metadata[\"timestamp\"]}.json'\n",
       "with open(output_file, 'w') as f:\n",
       "    json.dump(analysis_output, f, indent=2)\n",
       "\n",
       "print(f\"\\nAnalysis results saved to: {output_file}\")"
      ]
     }
    ],
    "metadata": {
     "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
     },
     "language_info": {
      "codemirror_mode": {
       "name": "ipython",
       "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
     }
    },
    "nbformat": 4,
    "nbformat_minor": 4
   }